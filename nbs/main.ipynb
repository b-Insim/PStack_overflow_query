{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp production.__main__\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catégorisez automatiquement des questions\n",
    "\n",
    "> Ce notebook présente un algorithme de machine Learning qui assugne automatiquement des Tags pertinents à une question du site Stack Overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# tables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# graphics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# expressions\n",
    "import re\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Deal with html text\n",
    "from bs4 import BeautifulSoup\n",
    "# Multiprocessing\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concaténations de tous les inputs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus on a des données d'entrées mieux c'est. Nous avons effectué 10  requêtes SQL afin d'avoir 10 fichiers csv: QueryResults.csv, QueryResults(1).csv à QueryResults(9).csv. Ces fichiers ont été générés en respectant la consignes qui demandait de faire des requêtes avec des contraintes sur les id.  Nos requêtes SQL ont été effectué sur les id compris entre 0 et 50 000. Chaque requête a pris les résultats non nuls dans une plage de 100 000 valeurs. Il y a eu différentes requêtes afin d'avoir des fichiers d'une taille inférieure à 25Mb.\n",
    "\n",
    "Nous dump sql se trouve dans le fichier sql_requery.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df_main = pd.DataFrame(columns=[\"Id\", \"Title\", \"Body\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df_main = df_main.append(pd.read_csv(\"../input/QueryResults.csv\"), ignore_index = True)\n",
    "df_main = df_main.append(pd.read_csv(\"../input/QueryResults(1).csv\"), ignore_index = True)\n",
    "df_main = df_main.append(pd.read_csv(\"../input/QueryResults(2).csv\"), ignore_index = True)\n",
    "df_main = df_main.append(pd.read_csv(\"../input/QueryResults(3).csv\"), ignore_index = True)\n",
    "df_main = df_main.append(pd.read_csv(\"../input/QueryResults(4).csv\"), ignore_index = True)\n",
    "df_main = df_main.append(pd.read_csv(\"../input/QueryResults(5).csv\"), ignore_index = True)\n",
    "df_main = df_main.append(pd.read_csv(\"../input/QueryResults(6).csv\"), ignore_index = True)\n",
    "df_main = df_main.append(pd.read_csv(\"../input/QueryResults(7).csv\"), ignore_index = True)\n",
    "df_main = df_main.append(pd.read_csv(\"../input/QueryResults(8).csv\"), ignore_index = True)\n",
    "df_main = df_main.append(pd.read_csv(\"../input/QueryResults(9).csv\"), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection générale des données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to convert decimal to double in C#?\n",
      "Percentage width child element in absolutely positioned parent on Internet Explorer 7\n",
      "In C#, how do I calculate someone's age based on a DateTime type birthday?\n",
      "Calculate relative time in C#\n",
      "Determine a user's timezone\n",
      "Difference between Math.Floor() and Math.Truncate()\n",
      "Filling a DataSet or DataTable from a LINQ query result set\n",
      "Binary Data in MySQL\n",
      "What is the fastest way to get the value of π?\n",
      "Throw an error in a MySQL trigger\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "for i in range(10):\n",
    "    print(df_main.loc[i, \"Title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons supprimer les caractères spéciaux et les ponctuations. Nous alons écrire une fonction qui prend en entrée un text, supprimer les caractères spéciaux, les ponctuations et enleve les majuscules.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pre_tokenize(text):\n",
    "    \n",
    "    # Suppression des points\n",
    "    text = text.replace('.', ' ')\n",
    "    # Suppressions des ponctuations\n",
    "    expr = [\"\\n\"] #[\"?\", \",\", \".\", \"'\", \";\", \":\", \"!\", \"\\n\", \"(\", \")\", \"|\", \"_\", \"-\", \"`\", \"+\", \"-\", \"*\", \"/\"]\n",
    "    for char in expr:\n",
    "        text = text.replace(char, ' ')\n",
    "    # Miniscule\n",
    "    text = str(np.char.lower(text))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df_main[\"Title\"] = df_main[\"Title\"].map(pre_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons aplliquer la Lemmatization afin de donner aux mots de notre texte une forme neutre. Nous le faisons dans la fonction suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lemmatize_text(text):\n",
    "\n",
    "    lem = WordNetLemmatizer()\n",
    "    text_lemmatized = []\n",
    "    words = word_tokenize(text)\n",
    "    for word in words:\n",
    "        word = lem.lemmatize(word, \"v\")\n",
    "        text_lemmatized.append(word)\n",
    "    text = ' '.join(text_lemmatized)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df_main[\"Title\"] = df_main[\"Title\"].map(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df_main[\"Title_tokens\"] = df_main[\"Title\"].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On est confronté à un problème, le 'word_tokenize' sépare les caractères comme «#» de «c#». Si \"C#\" est utilisé deux fois, le modèle trouvera deux mots identiques au lieu d'un. Additionnons tous les mots pour compter les fréquences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<c#><floating-point><type-conversion><double><decimal>\n",
      "<html><css><internet-explorer-7>\n",
      "<c#><.net><datetime>\n",
      "<c#><datetime><time><datediff><relative-time-span>\n",
      "<html><browser><timezone><user-agent><timezone-offset>\n",
      "<.net><math>\n",
      "<c#><linq><web-services><.net-3.5>\n",
      "<mysql><database><binary-data><data-storage>\n",
      "<performance><algorithm><language-agnostic><unix><pi>\n",
      "<mysql><database><triggers>\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "for i in range(10):\n",
    "    print(df_main.loc[i, \"Tags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparons les tags dans une liste pour mieux analyser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df_main[\"Tags\"] = df_main[\"Tags\"].map(lambda field:field[1:-1].split('><'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c#', 'floating-point', 'type-conversion', 'double', 'decimal']\n",
      "['html', 'css', 'internet-explorer-7']\n",
      "['c#', '.net', 'datetime']\n",
      "['c#', 'datetime', 'time', 'datediff', 'relative-time-span']\n",
      "['html', 'browser', 'timezone', 'user-agent', 'timezone-offset']\n",
      "['.net', 'math']\n",
      "['c#', 'linq', 'web-services', '.net-3.5']\n",
      "['mysql', 'database', 'binary-data', 'data-storage']\n",
      "['performance', 'algorithm', 'language-agnostic', 'unix', 'pi']\n",
      "['mysql', 'database', 'triggers']\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "for i in range(10):\n",
    "    print(df_main.loc[i, \"Tags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ajouter, du moins temporairement un champ dans le DataFrame principale. C'est le nombre de tags par posts. Il pourrait être utilisé pour obtenir une distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df_main[\"nb_tags\"] = df_main[\"Tags\"].map(lambda field:len(field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "sns.set()\n",
    "colors = sns.color_palette(\"hls\", 8)\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(df_main[\"nb_tags\"], color=colors[5])\n",
    "plt.title(\"Repartition du nombre de 'tags' par 'post'\")\n",
    "plt.ylabel(\"Nombre de tags\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs uniques et leurs proportions numériques donnent des informations sur les articles avec 5 tags. Nous pouvons maintenant lister toutes les tags et voir les fréquentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<p>I want to use a <code>Track-Bar</code> to change a <code>Form</code>\\'s opacity.</p>\\n<p>This is my code:</p>\\n<pre class=\"lang-cs prettyprint-override\"><code>decimal trans = trackBar1.Value / 5000;\\nthis.Opacity = trans;\\n</code></pre>\\n<p>When I build the application, it gives the following error:</p>\\n<blockquote>\\n<p>Cannot implicitly convert type <code>decimal</code> to <code>double</code></p>\\n</blockquote>\\n<p>I have tried using <code>trans</code> and <code>double</code> but then the <code>Control</code> doesn\\'t work. This code worked fine in a past VB.NET project.</p>\\n',\n",
       "       \"<p>I have an absolutely positioned <code>div</code> containing several children, one of which is a relatively positioned <code>div</code>. When I use a <code>percentage-based width</code> on the child <code>div</code>, it collapses to <code>0 width</code> on IE7, but not on Firefox or Safari.</p>\\n\\n<p>If I use <code>pixel width</code>, it works. If the parent is relatively positioned, the percentage width on the child works.</p>\\n\\n<ol>\\n<li>Is there something I'm missing here?</li>\\n<li>Is there an easy fix for this besides the <code>pixel-based width</code> on the\\nchild?</li>\\n<li>Is there an area of the CSS specification that covers this?</li>\\n</ol>\\n\",\n",
       "       \"<p>Given a <code>DateTime</code> representing a person's birthday, how do I calculate their age in years?</p>\\n\",\n",
       "       '<p>Given a specific <code>DateTime</code> value, how do I display relative time, like:</p>\\n\\n<ul>\\n<li>2 hours ago</li>\\n<li>3 days ago</li>\\n<li>a month ago</li>\\n</ul>\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "df_main.loc[0:3, \"Body\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gestion de la Majuscule et des points..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df_main[\"Body\"] = df_main[\"Body\"].map(pre_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons BeautifulSoup pour supprimer les tags html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_soup(text):\n",
    "    \"\"\" Retourne un texte , un soup sans tags html\"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df_main[\"Body_soup\"] = df_main[\"Body\"].map(lambda x: get_soup(x).get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df_main[\"Body_soup\"] = df_main[\"Body_soup\"].map(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df_main[\"Body_tokens\"] = df_main[\"Body_soup\"].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étudions aussi les fréquences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "np_text = df_main[\"Body_tokens\"].values.copy()\n",
    "full_body_text_splitted = []\n",
    "for i in range(len(np_text)):\n",
    "    full_body_text_splitted.extend(np_text[i])\n",
    "del np_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse des uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the                         379880\n",
       ",                           309035\n",
       "i                           289821\n",
       "to                          268225\n",
       "a                           221647\n",
       "                             ...  \n",
       "//overwrite                      1\n",
       "topixmap                         1\n",
       "aop=                             1\n",
       "coinit_disable_ole1dde           1\n",
       "includes/jquery/jquery-1         1\n",
       "Name: words, Length: 230588, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "df_count = pd.DataFrame({\"words\":full_body_text_splitted}).words.value_counts()\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "count = df_count.values\n",
    "unique = df_count.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['the', ',', 'i', 'to', 'a', ')', '(', \"''\", 'is', 'and', ':', 'in',\n",
       "       'of', '?', ';', 'that', 'it', 'this', '>', '<', 'for', '``',\n",
       "       'have', '=', 'on', 'be', 'with', 'but', 'do', 'my', 'if', 'not',\n",
       "       '{', 'as', '}', 'can', 'an', 'or', \"'\", \"n't\", 'there', 'are',\n",
       "       \"'m\", 'from', 'what', 'like', 'so', \"'s\", 'using', '[', ']',\n",
       "       'would', 'how', '--', 'you', 'any', 'when', 'use', 'code', 'way',\n",
       "       'some', 'which', 'does', 'am', 'get', 'at', '0', 'all', '$',\n",
       "       'file', '#', '1', 'new', 'want', 'one', 'data', 'will', 'we', 'by',\n",
       "       'has', 'class', 'need', 'just', 'application', '-', 'string',\n",
       "       'server', \"'ve\", 'know', 'me', 'c', '2', 'was', 'net', 'out',\n",
       "       'other', '!', 'then', 'should', 'user',\n",
       "       'm_permresource_radiobuttonlist', 'r_myrow', 'length-1-n',\n",
       "       \"'ix_indexname\", ':builder', 'ip_banlist', 'tag_extensions',\n",
       "       '\\\\231�027��w\\\\005\\\\b\\\\001\\\\000', 'drowning', \"ps1='\\\\u\",\n",
       "       'buttonvectorcleanup', '/var/www/mysite/js/common', 'contentvalue',\n",
       "       'non-openid', 'detectallviewresolvers', 'voilá', 'pureedge',\n",
       "       '//destination', 'strrestaurante', 'catalogrelationship',\n",
       "       'rootlogger=debug', 'overviewing', 'keller', 'createentries',\n",
       "       'lstfonts', 'pageid=1', \"'/blog/textile_to_html\", 'procedure_code',\n",
       "       'sms_queue', 'design\\\\2', 'secdoclienthandshake',\n",
       "       'xmlserializationreaderimageserverclientinterfacesoap',\n",
       "       \"'application/msword\", 'shlomi', 'stuff*',\n",
       "       'pythonimporterrorexception', 'hw_trans', '16l', 'hlemail',\n",
       "       'bstrexch', 'zoredache', 'usercontroldemo', '1\\\\log', 'prtbuf',\n",
       "       'easier/better/recommended', 'cityidx++', 'morefacets',\n",
       "       'individual2', 'sentimental', 'comitts', 'feedback_messages/index',\n",
       "       'prosecuted', '0x0800', 'lppoint', 'shabby', '*writablepath',\n",
       "       'three-phase', 'org/lists/lua-l/2002-02/msg00312', 'callopenonce',\n",
       "       'my_source_code2/', \"'f13e1f32-dc92-4c4a-b84d-34a59fe32063\",\n",
       "       '19958', '2009/02/18', 'library/navigation', 'set-operations',\n",
       "       'etags-tags-apropos', 'objectdeletedexception', 'dst_y', 'zeitsev',\n",
       "       'org/eclipse/downloads/drops/r-3', '01d3fc08', 'memeberclass',\n",
       "       '/chris/', '2,8,4,6', 'nonprofit', 'java:2211',\n",
       "       'geturlcacheentryinfo', '*value++', '0a\\\\include\\\\odbcss', '6,5',\n",
       "       '/controller/home', 'esitmate', 'settings/username/my',\n",
       "       'visiblityproperty', 'entityinfo', 'filegrid_book', '//dom',\n",
       "       'barneyton', 'implememt', \"style='top:55px\",\n",
       "       'someoutputpathfordll', 'tcp_closed', 'c:189', '10:00am-11:00am',\n",
       "       \"'projectfile\", '//overwrite', 'topixmap', 'aop=',\n",
       "       'coinit_disable_ole1dde', 'includes/jquery/jquery-1'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "np.concatenate((unique[0:100], unique[-100:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([379880, 309035, 289821, 268225, 221647, 210044, 207550, 143998,\n",
       "       140726, 131704, 130871, 119345, 115734, 105217, 101969, 100823,\n",
       "        99740,  90986,  89389,  80334,  77259,  66360,  65193,  61084,\n",
       "        54593,  53647,  52121,  52094,  50321,  45484,  45042,  44503,\n",
       "        43263,  43155,  42859,  42170,  42148,  38687,  37736,  36796,\n",
       "        36524,  35648,  35273,  35232,  34244,  33859,  32523,  32167,\n",
       "        31668,  31235,  31125,  30856,  30729,  29567,  28724,  27673,\n",
       "        26420,  26173,  25854,  25053,  24610,  23877,  23067,  22740,\n",
       "        22526,  22272,  22208,  22202,  22105,  21624,  21503,  21227,\n",
       "        20896,  20851,  20328,  18333,  18034,  17630,  17455,  17317,\n",
       "        17240,  17151,  17007,  16764,  16691,  16526,  16387,  16259,\n",
       "        16198,  15069,  14802,  14730,  14701,  14679,  14436,  14268,\n",
       "        14110,  14073,  14034,  13824,  13638,  13533,  13052,  12896,\n",
       "        12888,  12741,  12652,  12551,  12535,  12438,  12400,  12231,\n",
       "        12163,  11737,  11674,  11566,  11553,  11223,  11130,  11038,\n",
       "        11015,  10987,  10769,  10754,  10463,  10454,  10448,  10440,\n",
       "        10311,  10287,  10234,  10080,  10019,   9940,   9851,   9786,\n",
       "         9687,   9582,   9570,   9500,   9460,   9457,   9404,   9389,\n",
       "         9361,   9331,   9254,   9244,   9102,   9001,   8934,   8893,\n",
       "         8718,   8701,   8673,   8583,   8447,   8443,   8295,   8278,\n",
       "         8229,   8082,   8048,   8029,   8004,   8003,   7967,   7841,\n",
       "         7781,   7606,   7548,   7481,   7453,   7358,   7316,   7310,\n",
       "         7267,   7208,   7204,   7172,   7147,   7034,   7007,   6996,\n",
       "         6953,   6929,   6923,   6898,   6831,   6756,   6750,   6668,\n",
       "         6638,   6632,   6559,   6521,   6469,   6418,   6381,   6340,\n",
       "         6334,   6276,   6251,   6248,   6194,   6145,   6106,   6104,\n",
       "         6094,   6086,   6069,   6047,   5968,   5939,   5926,   5886,\n",
       "         5879,   5865,   5785,   5740,   5734,   5711,   5695,   5593,\n",
       "         5564,   5551,   5471,   5437,   5433,   5377,   5351,   5340,\n",
       "         5297,   5294,   5287,   5267,   5236,   5211,   5179,   5158,\n",
       "         5113,   5064,   5027,   5009,   4991,   4989,   4963,   4952,\n",
       "         4907,   4906,   4881,   4863,   4856,   4828,   4818,   4806,\n",
       "         4784,   4763,   4756,   4734,   4699,   4684,   4658,   4646,\n",
       "         4616,   4550,   4506,   4484,   4478,   4459,   4453,   4432,\n",
       "         4401,   4399,   4391,   4388,   4368,   4356,   4355,   4342,\n",
       "         4341,   4328,   4289,   4267,   4256,   4255,   4182,   4178,\n",
       "         4170,   4148,   4148,   4128,   4123,   4101,   4057,   4047,\n",
       "         4005,   3999,   3988,   3985,   3978,   3978,   3957,   3934,\n",
       "         3890,   3868,   3862,   3857,   3823,   3815,   3806,   3799,\n",
       "         3795,   3795,   3734,   3709,   3702,   3699,   3686,   3684,\n",
       "         3663,   3632,   3625,   3624,   3617,   3593,   3589,   3584,\n",
       "         3576,   3570,   3570,   3560,   3550,   3541,   3540,   3534,\n",
       "         3530,   3519,   3498,   3486,   3486,   3485,   3446,   3440,\n",
       "         3429,   3423,   3409,   3393,   3389,   3375,   3366,   3363,\n",
       "         3349,   3318,   3317,   3316,   3309,   3298,   3294,   3274,\n",
       "         3270,   3268,   3249,   3243,   3243,   3235,   3229,   3227,\n",
       "         3218,   3205,   3205,   3204,   3204,   3191,   3180,   3177,\n",
       "         3175,   3168,   3163,   3163,   3158,   3153,   3151,   3148,\n",
       "         3141,   3136,   3113,   3111,   3103,   3101,   3099,   3091,\n",
       "         3088,   3070,   3070,   3064,   3061,   3052,   3036,   3031,\n",
       "         3017,   3013,   2992,   2989,   2981,   2969,   2962,   2953,\n",
       "         2952,   2929,   2916,   2910,   2906,   2892,   2883,   2881,\n",
       "         2871,   2854,   2832,   2827,   2811,   2804,   2793,   2788,\n",
       "         2732,   2720,   2719,   2717,   2715,   2713,   2671,   2668,\n",
       "         2668,   2667,   2661,   2659,   2641,   2637,   2632,   2619,\n",
       "         2612,   2605,   2603,   2598,   2584,   2571,   2549,   2532,\n",
       "         2521,   2521,   2506,   2498,   2498,   2492,   2486,   2486,\n",
       "         2483,   2465,   2459,   2459,   2457,   2453,   2444,   2435,\n",
       "         2427,   2427,   2416,   2413,   2409,   2407,   2397,   2393,\n",
       "         2390,   2385,   2384,   2384,   2375,   2358,   2342,   2333,\n",
       "         2329,   2328,   2325,   2323,   2319,   2317,   2314,   2313,\n",
       "         2312,   2300,   2297,   2297,   2294,   2287,   2280,   2279,\n",
       "         2278,   2277,   2275,   2270,   2262,   2260,   2253,   2248,\n",
       "         2247,   2239,   2238,   2230,   2211,   2203,   2201,   2195,\n",
       "         2191,   2183,   2182,   2182,   2168,   2166,   2160,   2158,\n",
       "         2137,   2137,   2135,   2132,   2125,   2118,   2116,   2116,\n",
       "         2110,   2108,   2104,   2104,   2089,   2087,   2085,   2085,\n",
       "         2081,   2081,   2080,   2076,   2075,   2070,   2069,   2066,\n",
       "         2044,   2038,   2036,   2031,   2026,   2025,   2025,   2024,\n",
       "         2022,   2022,   2022,   2021,   2019,   2015,   2015,   2010,\n",
       "         2004,   2000,   1996,   1994,   1994,   1990,   1984,   1972,\n",
       "         1971,   1969,   1965,   1965,   1962,   1956,   1956,   1949,\n",
       "         1947,   1945,   1944,   1942,   1940,   1930,   1929,   1929,\n",
       "         1924,   1924,   1923,   1921,   1920,   1920,   1918,   1917,\n",
       "         1911,   1907,   1903,   1900,   1897,   1891,   1891,   1882,\n",
       "         1881,   1870,   1865,   1862,   1850,   1850,   1847,   1837,\n",
       "         1836,   1831,   1827,   1816,   1812,   1807,   1807,   1805,\n",
       "         1803,   1801,   1800,   1800,   1789,   1788,   1781,   1769,\n",
       "         1764,   1762,   1756,   1755,   1750,   1748,   1746,   1738,\n",
       "         1734,   1728,   1719,   1716,   1711,   1710,   1708,   1699,\n",
       "         1699,   1696,   1694,   1686,   1685,   1681,   1678,   1675,\n",
       "         1671,   1669,   1669,   1665,   1658,   1653,   1652,   1649,\n",
       "         1641,   1638,   1637,   1634,   1633,   1627,   1626,   1623,\n",
       "         1621,   1620,   1613,   1611,   1609,   1609,   1609,   1608,\n",
       "         1604,   1602,   1602,   1601,   1601,   1598,   1598,   1597,\n",
       "         1596,   1594,   1588,   1588,   1584,   1583,   1580,   1580,\n",
       "         1576,   1575,   1574,   1573,   1570,   1563,   1560,   1559,\n",
       "         1556,   1553,   1553,   1551,   1546,   1545,   1541,   1539,\n",
       "         1533,   1531,   1530,   1529,   1524,   1524,   1522,   1521,\n",
       "         1519,   1516,   1516,   1514,   1512,   1512,   1512,   1510,\n",
       "         1503,   1503,   1501,   1497,   1492,   1489,   1488,   1486,\n",
       "         1485,   1482,   1482,   1467,   1466,   1461,   1460,   1459,\n",
       "         1458,   1458,   1458,   1457,   1456,   1455,   1454,   1453,\n",
       "         1448,   1448,   1447,   1446,   1446,   1442,   1441,   1441,\n",
       "         1438,   1436,   1436,   1434,   1433,   1433,   1433,   1431,\n",
       "         1430,   1429,   1428,   1421,   1419,   1418,   1416,   1413,\n",
       "         1412,   1410,   1403,   1399,   1398,   1397,   1396,   1396,\n",
       "         1395,   1391,   1384,   1382,   1378,   1374,   1372,   1370,\n",
       "         1366,   1366,   1365,   1364,   1362,   1361,   1359,   1355,\n",
       "         1354,   1354,   1352,   1348,   1348,   1348,   1347,   1346,\n",
       "         1343,   1341,   1339,   1338,   1338,   1336,   1335,   1334,\n",
       "         1334,   1331,   1329,   1326,   1326,   1322,   1316,   1312,\n",
       "         1311,   1310,   1307,   1307,   1305,   1304,   1303,   1297,\n",
       "         1297,   1293,   1291,   1291,   1289,   1288,   1287,   1286,\n",
       "         1282,   1281,   1280,   1279,   1278,   1278,   1278,   1277,\n",
       "         1274,   1271,   1268,   1262,   1258,   1257,   1257,   1256,\n",
       "         1251,   1249,   1247,   1245,   1244,   1242,   1238,   1238,\n",
       "         1237,   1237,   1234,   1234,   1232,   1230,   1225,   1224,\n",
       "         1223,   1223,   1212,   1210,   1209,   1209,   1206,   1205,\n",
       "         1204,   1202,   1201,   1198,   1197,   1195,   1194,   1190,\n",
       "         1188,   1188,   1187,   1186,   1184,   1180,   1180,   1179,\n",
       "         1179,   1179,   1178,   1176,   1176,   1175,   1166,   1163,\n",
       "         1159,   1156,   1155,   1154,   1153,   1152,   1151,   1150,\n",
       "         1148,   1148,   1146,   1144,   1143,   1142,   1141,   1137,\n",
       "         1130,   1128,   1125,   1125,   1122,   1121,   1120,   1116,\n",
       "         1109,   1108,   1107,   1106,   1106,   1105,   1105,   1105,\n",
       "         1103,   1103,   1099,   1098,   1096,   1095,   1094,   1094,\n",
       "         1093,   1093,   1092,   1092,   1090,   1086,   1084,   1083,\n",
       "         1081,   1081,   1080,   1074,   1071,   1068,   1064,   1059,\n",
       "         1057,   1054,   1054,   1052,   1050,   1050,   1047,   1047,\n",
       "         1043,   1043,   1043,   1042,   1041,   1039,   1034,   1033,\n",
       "         1033,   1031,   1030,   1030,   1028,   1027,   1027,   1025,\n",
       "         1023,   1023,   1021,   1020,   1019,   1019,   1019,   1015,\n",
       "         1014,   1013,   1012,   1012,   1011,   1008,   1007,   1006,\n",
       "         1006,   1003,   1002,   1002])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "count[np.where(count > 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['c1033', 'sqlbuddy\\', 'wellknowntypescache', 'listitemview',\n",
       "       '/path/executable/', '\\\\servername\\jones', '\\packed\\bin', '-ddebugger',\n",
       "       '1982-07-10', 'inmediatly',\n",
       "       ...\n",
       "       'someoutputpathfordll', 'tcp_closed', 'c:189', '10:00am-11:00am',\n",
       "       ''projectfile', '//overwrite', 'topixmap', 'aop=',\n",
       "       'coinit_disable_ole1dde', 'includes/jquery/jquery-1'],\n",
       "      dtype='object', length=127395)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "body_words_to_del = unique[np.where(count == 1)]\n",
    "body_words_to_del"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage et normalisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Traning set\" et \"testing set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "xtrain, xtest = train_test_split(df_main, random_state=0)\n",
    "\n",
    "df_test = df_main.loc[xtest.index]\n",
    "df_test = df_test.reset_index()\n",
    "df_test = df_test.drop(\"index\", axis=1)\n",
    "\n",
    "df_train = df_main.loc[xtrain.index]\n",
    "df_train = df_train.reset_index()\n",
    "df_train = df_train.drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons essayer différentes méthodes de nettoyage pour obtenir un \"bag of words\".\n",
    "\n",
    "- \"Classic bag of words\"(suppression des points, /n, html, minuscules, lematize):\n",
    "    1.Aucune suppression des mots.\n",
    "    2.Suppression des mots utilisés une seule fois.\n",
    "    3.À partie des mots utilisés une seule fois, suppression de ceux qui ne sont pas dans le dictionnaire (trop bizarres comme mots).\n",
    "    4.À partir des mots utilisés une seule fois, suppression des caractères spéciaux (*, +, -, ', #, nombres ... )\n",
    "    \n",
    "- \"bag of words\" avec suppression des \"stopwords\"(avec suppression des points, /n, html, minuscules, lematize), plus:\n",
    "    1.Aucune suppression de mots\n",
    "    2.Suppression des mots utilisés une seule fois\n",
    "    3.À partir des mots utilisés une seule fois, suppression de ceux qui ne sont pas dans le dictionnaire (les mots bizarres)\n",
    "    4.À partir des mots utilisés une seule fois, suppression des caractères spéciaux (*, +, -, ', #, nombres ...)\n",
    "    \n",
    "- \"bag of words\" TF-IDF(avec suppression des points, /n, html, minuscules, lematize), plus:\n",
    "    1.Ne supprimez aucun mot\n",
    "    2.Suppression des mots utilisés une seule fois\n",
    "    3.À partir des mots utilisés une seule fois, suppression de ceux qui ne sont pas dans le dictionnaire (trop étranges)\n",
    "    4.À partir des mots utilisés une seule fois, suppression des caractères spéciaux (*, +, -, ', #, nombres ... attachés aux mots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic Bag of word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Aucune suppression de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec la focntion copy() nous ferrons du cleaning facilement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Prendre le corpus dans les array.\n",
    "text_train = df_train[\"Body_soup\"].values.copy()\n",
    "text_test = df_test[\"Body_soup\"].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "debug = False\n",
    "if debug:\n",
    "    text_train = text_train[0:160]\n",
    "    text_test = text_test[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Création du transformeur\n",
    "vectorizer = CountVectorizer(dtype=np.uint8)\n",
    "# Tokenize build vocab\n",
    "vectorizer.fit(text_train)\n",
    "# Encodage du document\n",
    "vector = vectorizer.transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'would': 130070,\n",
       " 'like': 70588,\n",
       " 'to': 119653,\n",
       " 'know': 68642,\n",
       " 'how': 59315,\n",
       " 'much': 78390,\n",
       " 'disk': 40090,\n",
       " 'space': 110096,\n",
       " 'directory': 39812,\n",
       " 'is': 65239}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "dict(list(vectorizer.vocabulary_.items())[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification de la mémoire du \"bag of words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le 'bag of words' devrait avoir une taille de (55456 * 132883) en int8.\n",
      "La taille totale en mémoire sera de 59 Go.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "nrows = len(text_train)\n",
    "ncols = len(list(vectorizer.vocabulary_.items()))\n",
    "print(\"Le 'bag of words' devrait avoir une taille de ({} * {}) en int8.\".format(nrows, ncols))\n",
    "print(\"La taille totale en mémoire sera de {} Go.\".format(round(nrows * ncols * 8 / 1000000000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons reduire notre échantillons à 15.000 pour notre traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le tarining 'bag of words' devrait avoir une taille de12001 * 47229 in int8\n",
      "Ça taille totale en mémoire sera de 0.57Go\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "# Prendre le corpus dans les array.\n",
    "text_train = df_train.loc[0:int(15000 * 0.8), \"Body_soup\"].values.copy()\n",
    "text_test = df_test.loc[0:int(15000 * 0.2), \"Body_soup\"].values.copy()\n",
    "if debug:\n",
    "    text_train = text_train[0:160]\n",
    "    text_test = text_test[0:40]\n",
    "    \n",
    "# Création du transformeur\n",
    "vectorizer = CountVectorizer(dtype=np.uint8)\n",
    "# Tokenize build vocab\n",
    "vectorizer.fit(text_train)\n",
    "# Encodage du document\n",
    "vector = vectorizer.transform(text_train)\n",
    "\n",
    "nrows = len(text_train)\n",
    "ncols = len(list(vectorizer.vocabulary_.items()))\n",
    "print(\"Le tarining 'bag of words' devrait avoir une taille de{} * {} in int8\".format(nrows, ncols))\n",
    "print(\"Ça taille totale en mémoire sera de {}Go\".format(round(nrows * ncols * 1 / 1000000000, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons un \"bag of words\" dans lequel le nombre de lignes est égale au nombre de post, et le nombre de colonnes est égale au nombre total de mots uniques. La cellule sera le nombre d'occurrences de chaque mot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "reverse_dict = {}\n",
    "for word, number in vectorizer.vocabulary_.items():\n",
    "    reverse_dict[number] = word\n",
    "    \n",
    "bag_train = pd.DataFrame()\n",
    "bag_train = bag_train.append(pd.DataFrame(vector.toarray()))\n",
    "bag_train = bag_train.rename(columns=reverse_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la création du \"bag of words\" nous n'utiliserons que le \"training set\". Ceci dit, nous utilisons la méthode de la transformation vectorielle avec \"testing set\" et le vecteur fité sur le \"training set\". les mots présents dans le \"testing set\" serons supprimons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Encode document\n",
    "vector_test = vectorizer.transform(text_test)\n",
    "# Création du \"bag of words\"\n",
    "bag_test = pd.DataFrame()\n",
    "bag_test = bag_test.append(pd.DataFrame(vector_test.toarray()))\n",
    "bag_test = bag_test.rename(columns=reverse_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde du \"bag of words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bag_train[\"Id\"] = df_train[\"Id\"]\n",
    "bag_train[\"Tags\"] = df_train[\"Tags\"]\n",
    "bag_train[\"Train\"] = 1\n",
    "\n",
    "bag_test[\"Id\"] = df_test[\"Id\"]\n",
    "bag_test[\"Tags\"] = df_test[\"Tags\"]\n",
    "bag_test[\"Train\"] = 0\n",
    "\n",
    "bag_train = bag_train.append(bag_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boleynkenkem/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:2449: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block1_values] [items->Index(['Id', 'Tags'], dtype='object')]\n",
      "\n",
      "  encoding=encoding,\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "bag_train.to_hdf(\"../output/classic_bag1.h5\", index='False', key='stage', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "del bag_train\n",
    "del bag_test\n",
    "del vector\n",
    "del vectorizer\n",
    "del reverse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Suppression des mots utilisés une seule fois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplication des 'feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_train_test(nb_rows=0):\n",
    "    \"\"\" Prend en entrée les valeurs test et train en fonction des\n",
    "    valeurs de debug \"\"\"\n",
    "    \n",
    "    if nb_rows == 0:\n",
    "        text_train = df_train[\"Body_soup\"].values.copy()\n",
    "        text_test = df_test[\"Body_soup\"].values.copy()\n",
    "    else:\n",
    "        text_train = df_train.loc[0:int(nb_rows * 0.8), \"Body_soup\"].values.copy()\n",
    "        text_test = df_test.loc[0:int(nb_rows * 0.2), \"Body_soup\"].values.copy()        \n",
    "    \n",
    "    if debug:\n",
    "        text_train = text_train[0:16]\n",
    "        text_test = text_test[0:4]\n",
    "    \n",
    "    return text_train, text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "text_train, text_test = get_train_test(nb_rows = 15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_unique_text(text, pd_words_to_del):\n",
    "    \"\"\" À partir d'un texte et une liste de mots à supprimer, \n",
    "    retourne un texte cleaned sans ces mots. \"\"\"\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    pd_tokens = pd.DataFrame({\"words\":tokens})\n",
    "    pd_tokens = pd_tokens.loc[~pd_tokens[\"words\"].isin(pd_words_to_del[\"words\"].values)]\n",
    "    \n",
    "    return ' '.join(pd_tokens[\"words\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_unique_series(texts, pd_words_to_del, function, cores=1):\n",
    "    \"\"\" \n",
    "    À partir d'une serie de textes et de mots à supprimer, retourne une serie sans \n",
    "    ces mots. \n",
    "    \"\"\"\n",
    "    \n",
    "    if cores == 1:\n",
    "        new_texts = []\n",
    "        for i, text in enumerate(texts):\n",
    "            new_text = remove_unique_text(text, pd_words_to_del)\n",
    "            new_texts.append(new_text)\n",
    "    \n",
    "    else:\n",
    "        inputs = tqdm(texts)\n",
    "        new_texts = Parallel(n_jobs=cores)(delayed(function)(body, pd_words_to_del) for body in inputs)\n",
    "    \n",
    "    return new_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "pd_body_words_to_del = pd.DataFrame({\"words\":body_words_to_del})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "text_train = remove_unique_series(text_train, pd_body_words_to_del, remove_unique_text, 1)\n",
    "text_test = remove_unique_series(text_test, pd_body_words_to_del, remove_unique_text, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction du \"bag of words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_bag(text_train, text_test):\n",
    "    \"\"\" Prend deux series de textes, train et test, et retourne\n",
    "    un 'bag of words'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Créate du transformeur\n",
    "    vectorizer = CountVectorizer(dtype=np.uint8)\n",
    "    # Tokenize, build vocab\n",
    "    vectorizer.fit(text_train)\n",
    "    # Encodage document\n",
    "    vector = vectorizer.transform(text_train)\n",
    "    \n",
    "    reverse_dict = {}\n",
    "    for word, number in vectorizer.vocabulary_.items():\n",
    "        reverse_dict[number] = word\n",
    "\n",
    "    bag_train = pd.DataFrame()\n",
    "    bag_train = bag_train.append(pd.DataFrame(vector.toarray()))\n",
    "    bag_train = bag_train.rename(columns=reverse_dict)\n",
    "    \n",
    "    # Encodage test document\n",
    "    vector_test = vectorizer.transform(text_test)\n",
    "    # Création du 'bag of words'\n",
    "    bag_test = pd.DataFrame()\n",
    "    bag_test = bag_test.append(pd.DataFrame(vector_test.toarray()))\n",
    "    bag_test = bag_test.rename(columns=reverse_dict)\n",
    "    \n",
    "    return bag_train, bag_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bag_train, bag_test = create_bag(text_train, text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_bags(bag_train, bag_test, method, number):\n",
    "    \"\"\" Sauvegarde des bags avec les noms suivants '../output/<method>_bag<number>.csv' \"\"\"\n",
    "    \n",
    "    bag_train[\"Id\"] = df_train[\"Id\"]\n",
    "    bag_train[\"Tags\"] = df_train[\"Tags\"]\n",
    "    bag_train[\"Train\"] = 1\n",
    "\n",
    "    bag_test[\"Id\"] = df_test[\"Id\"]\n",
    "    bag_test[\"Tags\"] = df_test[\"Tags\"]\n",
    "    bag_test[\"Train\"] = 0\n",
    "\n",
    "    bag_train = bag_train.append(bag_test)\n",
    "    print(\"Le 'bag' entier a un nombre total de {} mots\".format(bag_train.shape[1]))\n",
    "    bag_train.to_hdf(\"../output/\" + method + \"_bag\" + number + \".h5\", index='False', key='stage', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le 'bag' entier a un nombre total de 33499 mots\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "save_bags(bag_train, bag_test, \"classic\", \"2\")\n",
    "del bag_train\n",
    "del bag_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. À partie des mots utilisés une seule fois, suppression de ceux qui ne sont pas dans le dictionnaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplication des 'features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "text_train, text_test = get_train_test(nb_rows = 15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppression des mots étranges, mots présents dans le dictionnaire, de notre fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "pd_words_to_del2 = pd.DataFrame({\"words\":body_words_to_del})\n",
    "pd_words_to_del2 = pd_words_to_del2.loc[~pd_words_to_del2[\"words\"].isin(words.words()).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "text_train = remove_unique_series(text_train, pd_words_to_del2, remove_unique_text, 1)\n",
    "text_test = remove_unique_series(text_test, pd_words_to_del2, remove_unique_text, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bag_train, bag_test = create_bag(text_train, text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le 'bag' entier a un nombre total de 34067 mots\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "save_bags(bag_train, bag_test, \"classic\", \"3\")\n",
    "del bag_train\n",
    "del bag_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. À partir des mots utilisés une seule fois, suppression des caractères spéciaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "text_train, text_test = get_train_test(nb_rows = 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_unique_without_spe_text(text, words_to_del):\n",
    "    \"\"\" À partir d'un texte et des mots à supprimés, \n",
    "        retourne un sans carcatères spéciaux. \"\"\"\n",
    "    \n",
    "\n",
    "    # Suppression des ponctuations\n",
    "    expr = [\"?\", \",\", \".\", \"'\", \";\", \":\", \"!\", \n",
    "            \"(\", \")\", \"{\", \"}\", \"[\", \"]\",\n",
    "            \"|\", \"_\", \"`\", \"'\", \"#\", \"&\", \"$\",\n",
    "            \"+\", \"-\", \"*\", \"/\", \"=\", \"<\", \">\",\n",
    "            \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "    for char in expr:\n",
    "        text = text.replace(char, ' ') \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-6ab8362c9e11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtext_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_unique_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_unique_without_spe_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtext_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_unique_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_unique_without_spe_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-d759d808915d>\u001b[0m in \u001b[0;36mremove_unique_series\u001b[0;34m(texts, pd_words_to_del, function, cores)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnew_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mnew_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_unique_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd_words_to_del\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mnew_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-847a842df8f2>\u001b[0m in \u001b[0;36mremove_unique_text\u001b[0;34m(text, pd_words_to_del)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpd_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpd_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mpd_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd_words_to_del\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#export\n",
    "text_train = remove_unique_series(text_train, np.nan, remove_unique_without_spe_text, 1)\n",
    "text_test = remove_unique_series(text_test, np.nan, remove_unique_without_spe_text, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bag_train, bag_test = create_bag(text_train, text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "save_bags(bag_train, bag_test, \"classic\", \"4\")\n",
    "del bag_train\n",
    "del bag_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Bag of words' Suppression des 'stopwords' - Frequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def remove_stopwords(df_bag):\n",
    "    \"\"\" À partir du 'bag of words' suppression des \n",
    "          'stopwords' \"\"\"\n",
    "    \n",
    "    # Suppression des colonnes sans mots\n",
    "    cols = np.array(df_bag.columns)\n",
    "    cols = np.delete(cols, np.where(~np.isin(cols, [\"Id\", \"Tags\", 'Train'], invert=True)))\n",
    "    \n",
    "    # Suppression des colonnes qui sont les 'stopwords'\n",
    "    col_to_del = []\n",
    "    for col in cols:\n",
    "        if col in stopwords.words():\n",
    "            col_to_del.append(col)\n",
    "            \n",
    "    df_bag.drop(col_to_del, axis=1, inplace=True)\n",
    "    \n",
    "    return df_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "df_bag = pd.read_hdf(\"output/classic_bag1.h5\", index='False', key='stage', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "print(\"Le 'bag' entier avait un nombre de {} mots\".format(df_bag.shape[1]))\n",
    "df_bag = remove_stopwords(df_bag)\n",
    "print(\"Le 'bag' entier a maintenant un nombre total de {} mots\".format(df_bag.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_bag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-f3b00c03e310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_bag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/stopwords_bag\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"1\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'False'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'stage'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_bag' is not defined"
     ]
    }
   ],
   "source": [
    "#export\n",
    "df_bag.to_hdf(\"output/stopwords_bag\" + \"1\" + \".h5\", index='False', key='stage', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
